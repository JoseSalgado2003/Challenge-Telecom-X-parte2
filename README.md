# üöÄ Telecom X - Parte 2: Predicci√≥n de Cancelaci√≥n de Clientes (Churn)

## üìå Prop√≥sito del Proyecto
El objetivo principal de este proyecto es **predecir la cancelaci√≥n (churn) de clientes** en la empresa de telecomunicaciones Telecom X. A trav√©s de la construcci√≥n de modelos de Machine Learning y el an√°lisis de variables relevantes (como el tiempo de contrato y el gasto total), buscamos anticiparnos a la p√©rdida de clientes y proporcionar informaci√≥n estrat√©gica para el desarrollo de campa√±as de retenci√≥n efectivas.

## üìÇ Estructura del Proyecto
El repositorio est√° organizado de la siguiente manera para facilitar su reproducibilidad:

* **`notebook_telecomX_parte2.ipynb`**: Cuaderno principal de Jupyter/Colab que contiene todo el c√≥digo, desde el preprocesamiento hasta la evaluaci√≥n de los modelos.
* **`datos_tratados.csv`**: Archivo CSV con el dataset limpio y procesado de la Fase 1, listo para el modelado predictivo.
* **`/visualizaciones`**: Carpeta que contiene las im√°genes exportadas de los gr√°ficos generados durante el an√°lisis (matrices de confusi√≥n, importancia de variables, etc.).
* **`README.md`**: Este archivo con la documentaci√≥n del proyecto.

## üõ†Ô∏è Proceso de Preparaci√≥n de Datos
Para asegurar el correcto funcionamiento de los algoritmos de Machine Learning, los datos pasaron por un riguroso preprocesamiento:

1. **Clasificaci√≥n de Variables:** Se identificaron y separaron las variables num√©ricas (como `Charges.Total` y `tenure`) de las categ√≥ricas (como `Contract` y `PaymentMethod`).
2. **Codificaci√≥n (Encoding):** Se aplic√≥ *One-Hot Encoding* (`pd.get_dummies`) para transformar las variables categ√≥ricas a un formato num√©rico binario, haci√©ndolas compatibles con los modelos predictivos.
3. **Manejo de Nulos:** Se eliminaron las filas con valores `NaN` para evitar errores en las fases de entrenamiento.
4. **Separaci√≥n de Datos:** El dataset se dividi√≥ en dos conjuntos utilizando `train_test_split`: **80% para entrenamiento** y **20% para prueba**, utilizando estratificaci√≥n (`stratify`) para mantener la proporci√≥n original de la variable objetivo.
5. **Balanceo de Clases:** Dado el desbalanceo natural del churn, se aplic√≥ la t√©cnica **SMOTE** (Synthetic Minority Over-sampling Technique) exclusivamente en los datos de entrenamiento.
6. **Normalizaci√≥n:** Se aplic√≥ `StandardScaler` a los datos de entrenamiento para estandarizar las escalas de las variables num√©ricas.

## üß† Modelizaci√≥n: Decisiones y Justificaciones
Se entrenaron y compararon diferentes modelos, tomando decisiones arquitect√≥nicas basadas en la naturaleza de cada algoritmo:

* **Regresi√≥n Log√≠stica:** Este modelo se aliment√≥ con los datos **normalizados**. *Justificaci√≥n:* Al basarse en la optimizaci√≥n de par√°metros y el c√°lculo de coeficientes, la Regresi√≥n Log√≠stica es muy sensible a la magnitud de las variables; sin normalizaci√≥n, las variables con escalas mayores dominar√≠an el modelo.
* **Random Forest:** Este modelo se entren√≥ con los datos **sin normalizar**. *Justificaci√≥n:* Los algoritmos basados en √°rboles de decisi√≥n realizan particiones basadas en reglas (umbrales) sobre cada variable individualmente, por lo que son completamente inmunes a la escala de los datos.

## üìä Insights del An√°lisis Exploratorio (EDA)
Durante el an√°lisis dirigido previo al modelado, se descubrieron patrones clave:
* **Tiempo de Contrato vs Cancelaci√≥n:** Los gr√°ficos de caja (boxplots) revelaron que los clientes con un `tenure` (tiempo de retenci√≥n) bajo tienen una probabilidad much√≠simo mayor de cancelar el servicio. Los primeros meses son cr√≠ticos.
* **Gasto Total:** Se observ√≥ que una facturaci√≥n mensual alta en contratos de corto plazo es un fuerte detonante para el churn.
* **Importancia de Variables:** Seg√∫n el modelo Random Forest, las variables que m√°s influyen en la decisi√≥n de abandono son el tipo de contrato, la permanencia y los cargos totales.

## üíª Instrucciones de Ejecuci√≥n
Para reproducir este an√°lisis en tu m√°quina local, sigue estos pasos:

1. **Clona el repositorio:**
   ```bash
   git clone [https://github.com/JoseSalgado2003/Challenge-Telecom-X-parte2.git]

2. **Instala las bibliotecas requeridas:**
    Aseg√∫rate de tener instalado Python 3.x y ejecuta el siguiente comando para instalar las dependencias:
    Bash

    ```pip install pandas numpy scikit-learn imbalanced-learn matplotlib seaborn

    Carga los datos:
    Verifica que el archivo datos_tratados.csv est√© en el mismo directorio
    que el cuaderno, o ajusta la ruta en la celda de lectura:
    pd.read_csv('datos_tratados.csv').

    Ejecuta el cuaderno:
    Abre notebook_telecomX_parte2.ipynb en Jupyter Notebook, JupyterLab o
    Google Colab, y ejecuta las celdas secuencialmente.

Desarrollado por [Jos√© Salgado / JoseSalgado2003]
